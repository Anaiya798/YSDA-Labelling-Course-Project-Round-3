# Проектный раунд 3. Распознавание каверов Яндекс Музыки  
### 1. Работа с данными  
* Было решено провести бинарную разметку (кавер/не кавер).  
* Толокерам для разметки отдали 2000 самых популярных песен на
Яндекс Музыке (сначала был создан один пул на ~1000 заданий (т.е. где-то на
половину), а затем 2-ой пул на оставшуюся половину).  
* Мы предложили следующий алгоритм определения кавера. Для начала по
приложенной ссылке можно перейти по ссылке на сам трек в Яндекс.Музыке и
посмотреть, нет ли рядом с названием песни пометки Cover/Remake/Remix.  Если такая пометка есть, значит, перед нами кавер. Далее можно попробовать
поискать песни в альбомах той же Яндекс. Музыки, где собраны исключительно российские и зарубежные каверы (нами были приложены
ссылки на 3 таких альбома). Если и в альбоме ничего найти не удалось, можно попробовать поискать историю песни в Интернете, введя в поисковую строку
название трека и автора, например, “уитни хьюстон I will always love you википедия”. Ссылки на Google и Яндекс были также добавлены в интерфейс
задания. Если и в Интернете никакой информации про кавер найти не удалось, песню отмечаем как оригинал.   
* Для выполнения заданий в каком-либо из основных пулов толокерам
необходимо было выполнить 10 тренировочных заданий (включали в себя 5
каверов и 5 оригиналов как российских, так и зарубежных исполнителей).  
* Порог прохождения тренировки - 90%.  
* В основном пуле на странице размещалось по 10 заданий: 9 обычных и одно
контрольное. Всего было заготовлено 23 контрольных задания с примерно
равным соотношением каверов и оригиналов.   
* Изначально мы в основном пуле требовали от пользователей точности на
контрольных заданиях (cover_quality) свыше 60%, т.к. сочли свои задания
сложными. Однако потом все же повысили порог до 80%, что привело к
улучшению качества. Минимальное время выполнения задания мы поставили
15 секунд, что тоже оказалось пренебрежимо мало и впоследствии было
увеличено до 60 секунд.  
* Для поощрения добросовестных толокеров мы использовали динамическое
ценообразование. Тем, чей cover_quality составил ≥81%, мы выплачивали 0.1$
за страницу, в противном случае - 0.07$ за страницу.  
* Перекрытие было установлено в 3.    
* Полученные результаты агрегировали по модели Dawid-Skene.  
* Было потрачено 66$ / 100$.  
* Для формирования датасета для обучения модели были дополнительно
запрошены тексты и timestamp выхода песен.  

### 2. Создание пайплайна обучения и тренировка моделей  
* Было решено использовать двухуровневую модель:  
  - На первом уровне - KNN на эмбеддингах от [Multilingual Sentence Bert](https://www.sbert.net/docs/pretrained_models.html#multi-lingual-models) — эмбеддинги обучались    таким образом, чтобы косинусное сходство было тем больше, чем ближе по смыслу находятся сравниваемые фразы (и наоборот). Эмбеддинги брались не от всего текста          песни, а от каждой (неповторяющейся) строчки: сделано это было для того, чтобы Sbert не страдал от “впихивания” в него длинной последовательности, к которой он        неподготовлен, + для того, чтобы можно было на уровне отдельных строк уловить совпадение текстов различных песен (которое невозможно было бы отловить на уровне        сравнений эмбеддингов непосредственно песен). Прим.: для данного трека в KNN’е ищется $k = 3$ ближайших соседа, которые получили наибольшую сумму косинусных близостей          строчек.
  - Далее мы обучили Catboost на определенном наборе наборе фичей: метаинформация о треке (timestamp загрузки в ЯМузыку, имеется ли в названии
    (или альтернативных названиях) трека ключевые слова “remix”, “cover” и пр.), мета-информация о ближайших соседях этого трека, полученная от KNN. Отклик модели -       явлеяется ли трек с таким набором фичей кавером или нет.    
* В качестве базы данных для KNN взято из разметки ~1200 треков с
имеющимися текстами (60% от размеченных данных), для обучения Catboost’а
~600 треков с текстами/без них (в этом случае выход KNN - NaN значения для
всех фич соседей), ~200 треков с текстами/без них для валидации данного
ансамбля.  





В [ноутбуке](https://github.com/uvd174/YSDA-Labelling-Course-Project-Round-3/blob/master/RuSBERT%20Tiny%20%2B%20Catboost%2C%20train.ipynb) `RuSBERT Tiny + Catboost, train.ipynb` находится код тренировки модели.

В [ноутбуке](https://github.com/uvd174/YSDA-Labelling-Course-Project-Round-3/blob/master/RuSBERT%20Tiny%20%2B%20Catboost%2C%20inference.ipynb) `RuSBERT Tiny + Catboost, inference.ipynb` лежит код для инференса модели. Обратите внимание, что в самом начале описываются пути для весов моделей и тестируемого датасета в формате `.csv` с содержанием, соответствующим файлу [train.csv](https://github.com/uvd174/YSDA-Labelling-Course-Project-Round-3/blob/master/train.csv).


Веса моделей лежат по этой [ссылке](https://drive.google.com/drive/folders/1sSLzWoIW37FDuttWE7TX7RMelGPeZjFM?usp=share_link).
